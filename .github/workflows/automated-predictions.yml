name: Automated Matchday Predictions

on:
  # Schedule to run twice daily at midnight and noon Europe/Berlin time
  # Note: GitHub Actions cron runs in UTC only, so these times approximate Europe/Berlin
  schedule:
    - cron: '0 23 * * *'  # ~Midnight Europe/Berlin (23:00 UTC = 00:00 CET, 01:00 CEST)
    - cron: '0 11 * * *'  # ~Noon Europe/Berlin (11:00 UTC = 12:00 CET, 13:00 CEST)
  
  # Allow manual triggering with model selection
  workflow_dispatch:
    inputs:
      model:
        description: 'OpenAI model to use for predictions'
        required: true
        default: 'o4-mini'
        type: choice
        options:
          - 'o4-mini'
          - 'o1'
      force_prediction:
        description: 'Force prediction even if verify passes'
        required: false
        default: false
        type: boolean

env:
  # Set default model for scheduled runs
  DEFAULT_MODEL: 'o4-mini'
  # Set timezone for consistent logging
  TZ: 'Europe/Berlin'

jobs:
  automated-predictions:
    name: Automated Matchday Predictions
    runs-on: ubuntu-latest
    
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
        
      - name: Setup .NET
        uses: actions/setup-dotnet@v4
        with:
          dotnet-version: '9.x'
          
      - name: Restore dependencies
        run: dotnet restore
        
      - name: Build project
        run: dotnet build --no-restore --configuration Release
        
      - name: Set model for run
        id: set-model
        run: |
          if [ "${{ github.event_name }}" = "workflow_dispatch" ]; then
            echo "model=${{ github.event.inputs.model }}" >> $GITHUB_OUTPUT
            echo "force_prediction=${{ github.event.inputs.force_prediction }}" >> $GITHUB_OUTPUT
          else
            echo "model=${{ env.DEFAULT_MODEL }}" >> $GITHUB_OUTPUT
            echo "force_prediction=false" >> $GITHUB_OUTPUT
          fi
          
      - name: Verify current predictions
        id: verify
        continue-on-error: true
        run: |
          echo "ðŸ” Verifying current matchday predictions..."
          dotnet run --project src/Orchestrator/Orchestrator.csproj --configuration Release -- verify --init-matchday --agent
        env:
          KICKTIPP_USERNAME: ${{ secrets.KICKTIPP_USERNAME }}
          KICKTIPP_PASSWORD: ${{ secrets.KICKTIPP_PASSWORD }}
          FIREBASE_PROJECT_ID: ${{ secrets.FIREBASE_PROJECT_ID }}
          FIREBASE_SERVICE_ACCOUNT_JSON: ${{ secrets.FIREBASE_SERVICE_ACCOUNT_JSON }}
          OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }}
          
      - name: Generate and post predictions
        if: steps.verify.outcome == 'failure' || steps.set-model.outputs.force_prediction == 'true'
        run: |
          echo "ðŸ¤– Generating predictions with model: ${{ steps.set-model.outputs.model }}"
          if [ "${{ steps.verify.outcome }}" = "failure" ]; then
            echo "ðŸ“ Predictions needed - verify command indicated missing or mismatched predictions"
          else
            echo "ðŸ”„ Force prediction enabled - running regardless of verify result"
          fi
          
          dotnet run --project src/Orchestrator/Orchestrator.csproj --configuration Release -- matchday "${{ steps.set-model.outputs.model }}" --override-kicktipp --verbose --agent
        env:
          KICKTIPP_USERNAME: ${{ secrets.KICKTIPP_USERNAME }}
          KICKTIPP_PASSWORD: ${{ secrets.KICKTIPP_PASSWORD }}
          FIREBASE_PROJECT_ID: ${{ secrets.FIREBASE_PROJECT_ID }}
          FIREBASE_SERVICE_ACCOUNT_JSON: ${{ secrets.FIREBASE_SERVICE_ACCOUNT_JSON }}
          OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }}
          
      - name: Final verification
        if: steps.verify.outcome == 'failure' || steps.set-model.outputs.force_prediction == 'true'
        run: |
          echo "âœ… Running final verification to confirm predictions were posted successfully..."
          dotnet run --project src/Orchestrator/Orchestrator.csproj --configuration Release -- verify --agent
        env:
          KICKTIPP_USERNAME: ${{ secrets.KICKTIPP_USERNAME }}
          KICKTIPP_PASSWORD: ${{ secrets.KICKTIPP_PASSWORD }}
          FIREBASE_PROJECT_ID: ${{ secrets.FIREBASE_PROJECT_ID }}
          FIREBASE_SERVICE_ACCOUNT_JSON: ${{ secrets.FIREBASE_SERVICE_ACCOUNT_JSON }}
          OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }}
          
      - name: Success notification
        if: steps.verify.outcome == 'success' && steps.set-model.outputs.force_prediction == 'false'
        run: |
          echo "âœ… All predictions are up to date - no action needed"
          
      - name: Workflow summary
        if: always()
        run: |
          echo "## Workflow Summary" >> $GITHUB_STEP_SUMMARY
          echo "- **Trigger**: ${{ github.event_name }}" >> $GITHUB_STEP_SUMMARY
          echo "- **Model**: ${{ steps.set-model.outputs.model }}" >> $GITHUB_STEP_SUMMARY
          echo "- **Timezone**: ${{ env.TZ }}" >> $GITHUB_STEP_SUMMARY
          echo "- **Verify Result**: ${{ steps.verify.outcome }}" >> $GITHUB_STEP_SUMMARY
          
          if [ "${{ steps.verify.outcome }}" = "failure" ] || [ "${{ steps.set-model.outputs.force_prediction }}" = "true" ]; then
            echo "- **Action**: Predictions generated and posted" >> $GITHUB_STEP_SUMMARY
          else
            echo "- **Action**: No predictions needed" >> $GITHUB_STEP_SUMMARY
          fi
